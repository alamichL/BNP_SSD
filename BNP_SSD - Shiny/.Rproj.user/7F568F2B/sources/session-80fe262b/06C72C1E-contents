## read sources

# source("~/Documents/PY_hyperprior_consistency-main/Code_SP_Mix/Random_SpMix.R")
# source("~/Documents/PY_hyperprior_consistency-main/scripts/Estimation_SPMix_2.R")
# source("~/Documents/PY_hyperprior_consistency-main/Code_SP_Mix/Identification_SpMix.R")

require(e1071)
require(mclust)
require(MASS)
require(bayesm)
require(MCMCpack)
require(mvtnorm)
require(Runuran)
require(flexclust)
library(gridExtra)
library(cowplot)
library(ggplot2)
library(abind)
library(parallel)
library(ggmcmc)
#---------- B) Specification of the simulation and prior parameters -----------------------------------------------

loadRData <- function(fileName){
  #loads an RData file, and returns it
  load(fileName)
  get(ls()[ls() != "fileName"])
}

compute_log_lik<- function(y, Eta, Mu, Sigma){
  n_data = dim(y)[1]
  plk = 0
  log_lik = c()
  for (i in 1:length(Eta)){
    eta = Eta[[i]]
    mu = Mu[[i]]
    sigma = Sigma[[i]]
    K = length(eta)
    lik = matrix(0,n_data,K)
    for (j in 1:K){
      lik[,j] = eta[j]*dmvnorm(y,mu[,j], sigma[,,j])
      #k_ = S_alt_matrix[j,i]
      #p_l <- sum(sapply(1:n_data, function(i) Eta[j,S_alt_matrix[j,i]] * dmvnorm(y[i,],Mu[j,,S_alt_matrix[j,i]], Sigma[j,,,S_alt_matrix[j,i]])))
      #k_ = S_alt_matrix[j,i]
      #plk = plk + Eta[j,k_] * dmvnorm(y[i,], Mu[j,,k_], Sigma[j,,,k_])
    }
    log_lik[i] = sum(log(apply(lik,1,sum)))
  }
  return(log_lik)
}

list_to_mat <- function(L, K=15, M, burnin, d){
  n_chains <- length(L)
  if(d==0){
    mat <- matrix(0, n_chains*M, K)
    for(i in 1:n_chains){
      l <- L[[i]]
      for(j in (burnin+1):(M+burnin)){
        k <- length(l[[j]])
        mat[(i-1)*M+(j-burnin),1:k] <- l[[j]] 
      }
    }
  }
  else if(d==1){
    r <- length(L[[1]][[1]][,1])
    mat <- array(0, dim=c(n_chains*M,r,K))
    for(i in 1:n_chains){
      l <- L[[i]]
      for(j in (burnin+1):(M+burnin)){
        D <- dim(l[[j]])
        mat[(i-1)*M+(j-burnin),1:D[1],1:D[2]] <- l[[j]]
      }
    }
  }
  else if(d==2){
    r <- length(L[[1]][[2]][,1,1])
    mat <- array(0, dim=c(n_chains*M,r,r,K))
    for(i in 1:n_chains){
      l <- L[[i]]
      for(j in (burnin+1):(M+burnin)){
        D <- dim(l[[j]])
        mat[(i-1)*M+(j-burnin),1:D[1],1:D[2],1:D[3]] <- l[[j]]
      }
    }
  }
  else print("not implemented")
  return(mat)
}


MCMC_function <- function(data, s0=0.5, M, burnin, n_chains, priorOnalpha=FALSE, priorOns0=FALSE, 
                          typePrior="beta", alpha=1, m_imp=10, a_gam=1, b_gam=20, a_beta=0.5, b_beta=2) {
  
  RNGkind("L'Ecuyer-CMRG")
  set.seed(1234)
  (s <- .Random.seed)
  
  y <- as.matrix(data$y)
  
  ## read dimensions of data:
  r <- length(y[1, ])
  N <- length(y[, 1])
  
  ## Dirichlet parameter for the mixture weights
  ## variance of the normal proposal for the MH step for estimating s0 and alpha
  c_proposal <- c(5,0.5)
  
  R <- apply(y, 2, function(x) diff(range(x)))
  
  ## prior on Sigma_k
  c0 <- 2.5 + (r - 1)/2
  C0 <- 0.75 * cov(y)
  g0 <- 0.5 + (r - 1)/2
  G0 <- 100 * g0/c0 * diag((1/R^2))
  
  ## prior on mu
  b0 <- apply(y, 2, median)
  B_0 <- rep(1, r)  #initial values for lambda are 1
  B0 <- diag((R^2) * B_0)
  nu <- 0.5
  
  #---------- C) Gibbs sampling from the posterior -----------------------------------------------
  ################ call MCMC procedure
  ############### run n_chains parallel chains
  data_list <- list()
  for(i in 1:n_chains)
    data_list[[i]] <- y
  mc.reset.stream()
  est_list <- mclapply(data_list, MultVar_NormMixt_Gibbs_IndPriorNormalgamma, s0=s0, alpha=alpha,
                       c0=c0, C0=C0, g0=g0, G0=G0, b0=b0, B0k=B0, nu=nu, lam_0=B_0, M=M, burnin=burnin, 
                       c_proposal=c_proposal, priorOnalpha=priorOnalpha, priorOns0=priorOns0, typePrior=typePrior, 
                       lambda=FALSE, m_imp=m_imp, a_gam=a_gam, b_gam=b_gam, a_beta=a_beta, b_beta=b_beta, 
                       mc.cores = 10, mc.set.seed = TRUE)
  
  acc_s0 <- c(sum(unlist(lapply(est_list, function(e){e$acc_rate_s0[1]})))/n_chains, 
              sum(unlist(lapply(est_list, function(e){e$acc_rate_s0[2]})))/n_chains)
  acc_al <- c(sum(unlist(lapply(est_list, function(e){e$acc_rate_alpha[1]})))/n_chains, 
              sum(unlist(lapply(est_list, function(e){e$acc_rate_alpha[2]})))/n_chains)
  cat("acceptance rate s0: after burnin ", acc_s0[1], ", with burnin ", acc_s0[2], "\n")
  cat("acceptance rate alpha: after burnin ", acc_al[1], ", with burnin ", acc_al[2], "\n")
 
  K_max <- lapply(est_list, function(e){e$Eta})
  K_max <- lapply(1:4, function(i){
      lapply(K_max[[i]], function(x) max(sum(x != 0)))
  }) %>% unlist %>% max
  cat("\n K_max ", K_max)
  K_bound = max(K_max,15)
  
  alpha_combined <- lapply(est_list, function(e){e$alpha_vector})
  s0_combined <- lapply(est_list, function(e){e$s0_vector})
  
  s0_prop <- lapply(est_list, function(e){e$s0_prop})
  par(mfrow=c(1,1))
  plot(1:length(s0_prop[[1]]), s0_prop[[1]], pch = 1, col=1, main = "S0 proposal", ylim = c(-1,10))
  lapply(2:n_chains, function(i){
    points(1:length(s0_prop[[i]]), s0_prop[[i]], pch = i, col=i, xlab = paste("iteration"), lty=2)
  })
  print(sum(unlist(s0_prop)<1 & unlist(s0_prop)>0))
  ### Storing without burnin
  Eta_combined <- list_to_mat(lapply(est_list, function(e){e$Eta}), K_bound, M, burnin, 0)
  Mu_combined <- list_to_mat(lapply(est_list, function(e){e$Mu}), K_bound, M, burnin, 1)                                
  Sigma_combined <- list_to_mat(lapply(est_list, function(e){e$Sigma}), K_bound, M, burnin, 2)
  Nk_matrix_alt <- lapply(est_list, function(e){e$Nk_matrix_alt[(burnin+1):(M+burnin)]})
  

  ################## Likelihood ########################
  par(mfrow=c(1,2))
  # compute log-likelihood for each chain
  ll_list <- lapply(est_list, function(e){compute_log_lik(y, e$Eta, e$Mu, e$Sigma)})
  
  ## convergence diagnostics
  log_lik_combines <- mcmc.list(lapply(ll_list, function(l){mcmc(l)}))
  plot(1:length(ll_list[[1]]), ll_list[[1]], type = "l", col=1, xlab = paste("iteration"), main = "likelihood")
  lapply(2:n_chains, function(i){
    lines(1:length(ll_list[[i]]), ll_list[[i]], col=i, xlab = paste("iteration"), lty=2)
    })
  Rhat_ll<- gelman.diag(log_lik_combines)$psrf[1]
  cat("\n R_hat ", Rhat_ll)
  
  #### number of nonempty components (nne_gr), after burnin:
  Nk_matrix_alt_list <- lapply(est_list, function(e){e$Nk_matrix_alt})
  nne_c <- function(Nk){unlist(lapply(Nk, function(x) sum(x != 0)))} #vector with number of non-empty groups of each iteration
  K_0_list <- lapply(Nk_matrix_alt_list, nne_c)
  plot(1:length(K_0_list[[1]]), K_0_list[[1]], type = "l", col=1, xlab = paste("iteration"), main = "Nb non-empty components")
  lapply(2:n_chains, function(i){
    lines(1:length(K_0_list[[i]]), K_0_list[[i]], col=i, xlab = paste("iteration"), lty=2)
  })

  # S <- mcmc.list(lapply(1:n_chains, function(i){
  #   mcmc(data.frame(Lik=ll_list[[i]], Sig=est_list[[i]]$s0_vector, Al=est_list[[i]]$alpha_vector, K=K_0_list[[i]]))
  #   }))
  # gs <- ggs(S, burnin=burnin)
  # if(priorOnalpha && priorOns0)
  #   ggmcmc(gs, file = paste0("~/Documents/Louise/PY_hyperprior_consistency-main/conv_diag/PY",N,"_alpha_G_",a_gam,"_",b_gam,"_sigma_",typePrior,"_",a_beta,"_",b_beta,".pdf"),
  #          param_page = 2)
  # else if(priorOnalpha)
  #   ggmcmc(gs, file = paste0("~/Documents/Louise/PY_hyperprior_consistency-main/conv_diag/PY",N,"_alpha_G_",a_gam,"_",b_gam,"_sigma_",s0,".pdf"),
  #          param_page = 2)
  # else if(priorOns0)
  #   ggmcmc(gs, file = paste0("~/Documents/Louise/PY_hyperprior_consistency-main/conv_diag/PY",N,"_alpha_",alpha,"_sigma_",typePrior,"_",a_beta,"_",b_beta,".pdf"),
  #          param_page = 2)
  # else
  #   ggmcmc(gs, file = paste0("~/Documents/Louise/PY_hyperprior_consistency-main/conv_diag/PY",N,"_alpha_",alpha,"_sigma_",s0,".pdf"),
  #          param_page = 2)

  
  #---------- E) Identification of the mixture model -----------------------------------------------
  ##### estimating the number of nonempty components without burnin
  K0_M <- lapply(Nk_matrix_alt, nne_c)
  p_K0 <- tabulate(unlist(K0_M), K_bound)
  
  #par(mfrow = c(1, 1))
  #barplot(p_K0, names = 1:K, xlab = "number of non-empty groups K0", col = "green", ylab = "freq")
  K0 <- which.max(p_K0)
  print(paste("mode: ", K0)) #mode K0 is the estimator for K_true
  M0 <- sum(unlist(K0_M) == K0)
  print(paste("nb of draws with K0 non-empty groups: ", M0))  #M0 draws have exactly K0 non-empty groups
  
  return(list(p_k=p_K0, p_k_all=unlist(K0_M), Eta=Eta_combined, Mu=Mu_combined, Sigma=Sigma_combined, alpha=alpha_combined, s0=s0_combined)) # K_max=K_max,
}


comparison_prior <- function(ds_list, M_it, nburn, n_chains, s0=0.5, alpha=1, 
                             priorOnalpha=FALSE, priorOns0=FALSE, typePrior="unif", a_g=1, b_g=20, a_beta=0.5, b_beta=2){
  pk <- list()
  N <- c()
  R_h <- c()
  W_non_sorted <- list()
  W <- list()
  Mu_mat <- list()
  S_mat<- list()
  Alpha <- list()
  S0 <- list()
  K_max <- 15
  for (i in 1:length(ds_list)){
    data =  loadRData(ds_list[i])
    pk[[i]] <- MCMC_function(data, n_chains=n_chains, priorOnalpha=priorOnalpha, priorOns0=priorOns0, typePrior=typePrior,
                             alpha=alpha, s0=s0, M=M_it, burnin=nburn, a_gam=a_g, b_gam=b_g, a_beta=a_beta, b_beta=b_beta)
    N[i]<- dim(data$y)[1]
    #Eta_ <- apply(pk[[1]]$Eta , 2, function(x) c(sort(x, decreasing = TRUE)))
    Eta_<- matrix(NA, nrow =dim(pk[[i]]$Eta)[1],ncol =  dim(pk[[i]]$Eta)[2] )
    for (j in 1:dim(pk[[i]]$Eta)[1]){ Eta_[j,] <- sort(pk[[i]]$Eta[j,],decreasing = TRUE)}
    W[[i]] <- Eta_
    W_non_sorted[[i]] <- pk[[i]]$Eta
    Mu_mat[[i]] <- pk[[i]]$Mu
    S_mat[[i]] <-pk[[i]]$Sigma
    # if(pk[[i]]$K_max > K_max)
    #   K_max = pk[[i]]$K_max
    if(priorOnalpha)
      Alpha[[i]]<- pk[[i]]$alpha
    if(priorOns0)
      S0[[i]]<- pk[[i]]$s0
  }

  # Resize W
  if(length(W[[i]])<K_max){
    W <- lapply(W, function(x){c(x,rep(0,K_max-ncol(x)))}) 
    W_non_sorted <- lapply(W_non_sorted, function(x){c(x,rep(0,K_max-ncol(x)))}) 
  } else{
    W <- lapply(W, function(x){x[1:K_max]})
    W_non_sorted <- lapply(W_non_sorted, function(x){x[1:K_max]})
  }
  
  df_ = tibble(K= 1:K_max)
  df3_ = tibble(K= 1:K_max)
  df4_ = tibble(K= 1:K_max)
  for (j in 1:length(ds_list)){
    name_ <- paste("Pkn_", j, sep = "")
    name3_ <- paste("N_", j, sep = "")
    name4_ <- paste("W_", j, sep = "")
    p_k <- tabulate(pk[[j]]$p_k_all, K_max)
    df_[,name_]<- p_k
    df3_[,name3_]<- rep(N[j],length(p_k))
    df4_[,name4_]<- rep(N[j],length(p_k))
  }
  df = df_%>% gather(Process_type, density,  paste("Pkn_", 1, sep = ""):paste("Pkn_", length(ds_list), sep = ""))
  df3 = df3_%>% gather(N_, N_val,  paste("N_", 1, sep = ""):paste("N_", length(ds_list), sep = ""))
  df4 = df4_%>% gather(W_, W_val,  paste("W_", 1, sep = ""):paste("W_", length(ds_list), sep = ""))
  W_df <- do.call(cbind, W)
  df4_post <- cbind(df4,t(W_df))
  df4_post_ <- gather(df4_post, key = "it",value="weights", 4: dim(df4_post)[2])
  if(!priorOnalpha)
    df$alpha = c(rep(alpha,dim(df_)[1]*length(ds_list)))
  if(!priorOns0)
    df$s0 = c(rep(s0,dim(df_)[1]*length(ds_list))) 
  df$N =df3$N_val
  
  df_l_ = tibble(K= 1:(M_it*n_chains))
  df3_l_ = tibble(K= 1:(M_it*n_chains))
  for (j in 1:length(ds_list)){
    name_ <- paste("P_", j, sep = "")
    name3_ <- paste("N_", j, sep = "")
    df_l_[,name_] <- pk[[j]]$p_k_all
    df3_l_[,name3_] <- rep(N[j], length(pk[[j]]$p_k_all))
  }
  df_l = df_l_%>% gather(Process_type, density,  paste("P_", 1, sep = ""):paste("P_", length(ds_list), sep = ""))
  df_l3 = df3_l_%>% gather(N_, N_val,  paste("N_", 1, sep = ""):paste("N_", length(ds_list), sep = ""))
  if(!priorOnalpha)
    df_l$alpha = c(rep(alpha,M_it*n_chains*length(ds_list))) 
  if(!priorOns0)
    df_l$s0 = c(rep(s0,M_it*n_chains*length(ds_list)))
  df_l$N =df_l3$N_val
  # Output
  if(!priorOns0)
    result <- list(line=df, hist=df_l, weights=df4_post_, eta = W_non_sorted, mu=Mu_mat, sig=S_mat, alpha=Alpha)
  if(!priorOnalpha)
    result <- list(line=df, hist=df_l, weights=df4_post_, eta = W_non_sorted, mu=Mu_mat, sig=S_mat, s0=S0)
  if(priorOnalpha && priorOns0)
    result <- list(line=df, hist=df_l, weights=df4_post_, eta = W_non_sorted, mu=Mu_mat, sig=S_mat, alpha=Alpha, s0=S0)
  return(result)
}
